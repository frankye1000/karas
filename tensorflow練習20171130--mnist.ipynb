{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如同在 scikit-learn 套件中讀入 iris 一般，在 TensorFlow 套件中讀入 MNIST 同樣是很容易的，不論是訓練資料或者測試資料，都有分 images 與 labels 屬性，我們簡單跟 scikit-learn 套件做個對照：\n",
    "\n",
    "套件\t自變數 X\t目標變數 y\n",
    "sklearn\tdata\ttarget\n",
    "tensorflow\timages\tlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import pprint\n",
    "# mnist\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test  = mnist.test.images\n",
    "y_test  = mnist.test.labels\n",
    "\n",
    "# 檢視溝通\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# 檢視一個觀測值\n",
    "print(np.argmax(y_train[9,:])) #第一章訓練照片的答案(傳回index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 的圖片是 28 像素 x 28 像素，每一張圖片就可以用 28 x 28 = 784 個數字來紀錄，因此 print(x_train.shape) 的輸出告訴我們有 55,000 張訓練圖片，每張圖片都有 784 個數字；而 print(y_train.shape) 的輸出告訴我們的是這 55,000 張訓練圖片的真實答案，print(np.argmax(y_train[1, :])) 的輸出告訴我們第一張訓練圖片的真實答案為 3。\n",
    "\n",
    "我們也可以使用 matplotlib.pyplot 把第一張訓練圖片印出來看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x139bd5344e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "\n",
    "#印出來看看\n",
    "first_train_img = np.reshape(x_train[9, :], (28, 28))\n",
    "plt.matshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸入向量 [1,2,3,4,1,2,3]對應的Softmax函數的值為 [0.024,0.064,0.175,0.475,0.024,0.064,0.175]。輸出向量中擁有最大權重的項對應著輸入向量中的最大值「4」。這也顯示了這個函數通常的意義：對向量進行歸一化，凸顯其中最大的值並抑制遠低於最大值的其他分量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.718281828459045, 7.38905609893065, 20.085536923187668, 54.598150033144236, 2.718281828459045, 7.38905609893065, 20.085536923187668]\n",
      "114.98389973429897\n",
      "[0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "z = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0]\n",
    "z_exp = [math.exp(i) for i in z]  \n",
    "print(z_exp)  # Result: [2.72, 7.39, 20.09, 54.6, 2.72, 7.39, 20.09] \n",
    "\n",
    "sum_z_exp = sum(z_exp)  \n",
    "print(sum_z_exp)  # Result: 114.98 \n",
    "\n",
    "softmax = [round(i / sum_z_exp, 3) for i in z_exp]\n",
    "print(softmax)  # Result: [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax 函數\n",
    "\n",
    "我們需要透過 Softmax 函數將分類器輸出的分數（Evidence）轉換為機率（Probability），然後依據機率作為預測結果的輸出，可想而知深度學習模型的輸出層會是一個 Softmax 函數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy\n",
    "\n",
    "不同於我們先前使用 Mean Squared Error 定義 Loss，在這個深度學習模型中我們改用 Cross-entropy 來定義 Loss。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "1.82941\n",
      "0.469246\n",
      "0.289489\n",
      "0.324289\n",
      "0.257896\n",
      "0.31448\n",
      "0.181592\n",
      "0.177683\n",
      "0.195215\n",
      "0.305716\n",
      "0.306865\n",
      "0.185438\n",
      "0.175632\n",
      "0.254565\n",
      "0.275598\n",
      "0.303582\n",
      "0.209751\n",
      "0.303232\n",
      "0.479393\n",
      "0.157202\n",
      "---\n",
      "Accuracy:  0.9181\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# 設定參數\n",
    "learning_rate = 0.5\n",
    "training_steps = 1000\n",
    "batch_size = 100\n",
    "logs_path = 'Tensorflow/'\n",
    "n_features = x_train.shape[1]\n",
    "n_labels = y_train.shape[1]\n",
    "\n",
    "# 建立 Feeds\n",
    "with tf.name_scope('Inputs'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_features], name = 'Input_Data')\n",
    "with tf.name_scope('Labels'):\n",
    "    y = tf.placeholder(tf.float32, [None, n_labels], name = 'Label_Data')\n",
    "\n",
    "# 建立 Variables\n",
    "with tf.name_scope('ModelParameters'):\n",
    "    W = tf.Variable(tf.zeros([n_features, n_labels]), name = 'Weights')\n",
    "    b = tf.Variable(tf.zeros([n_labels]), name = 'Bias')\n",
    "\n",
    "# 開始建構深度學習模型\n",
    "with tf.name_scope('Model'):\n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "with tf.name_scope('CrossEntropy'):\n",
    "    # Cross-entropy\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction), reduction_indices = 1))\n",
    "    tf.summary.scalar(\"Loss\", loss)\n",
    "with tf.name_scope('GradientDescent'):\n",
    "    # Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('Accuracy', acc)\n",
    "\n",
    "# 初始化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 開始執行運算\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 將視覺化輸出\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logs_path, graph = tf.get_default_graph())\n",
    "\n",
    "# 訓練\n",
    "for step in range(training_steps):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(optimizer, feed_dict = {x: batch_xs, y: batch_ys})\n",
    "    if step % 50 == 0:\n",
    "        print(sess.run(loss, feed_dict = {x: batch_xs, y: batch_ys}))\n",
    "        summary = sess.run(merged, feed_dict = {x: batch_xs, y: batch_ys})\n",
    "        writer.add_summary(summary, step)\n",
    "\n",
    "print(\"---\")\n",
    "# 準確率\n",
    "print(\"Accuracy: \", sess.run(acc, feed_dict={x: x_test, y: y_test}))\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
