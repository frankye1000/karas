{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://10.120.37.108:27017\")\n",
    "db = client[\"fb_cleaned\"]\n",
    "collection = db[\"message_cleaned\"]\n",
    "messages_score = list(collection.find({},{\"_id\":0,\"politician_id\":0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages_list = [m for m in messages_score if len(m[\"message\"]) >=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(messages_list)\n",
    "text = df[\"message\"].values\n",
    "y = df[\"score\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '稅收 讓利 企業 誘使 企業 員工 直接 加薪 雙面 有利 很好 將心 比心 企業 短入 荷包 分享 員工 政府 讓利 企業 很好 方法 其實 簡單 薪資 費用 加乘 倍率 承認 薪資 費用 薪資 費用 達到 收入 申報 減乘 計算 薪資 費用 勞健 保險費 一律 薪資 費用 投保 導正 海外 就業 人口 依未 境內 天數 來加 加乘 費率 計收 保險費 導正 不公平 健保',\n",
       "       '對馬 弊案 有點 進展 值得 稱讚 根本 進展 樂聲 弊案 銀行 洗錢 百多 慶富 關心 一粒 一休 企業 起薪 企業 老闆 不肯 賴清德 縮回去 下文',\n",
       "       '賴清德 加油 希望 完善 便捷 公車 運輸 系統 搭車 價格 騎乘 機車 太多 吸引 民眾 騎乘 機車 搭乘 公車 轉換 捷運 輕軌 公共 運輸 系統 減少 發生 機車 死亡 車禍 機會 觀光 遊憩 資源 吸引 更多 海外 觀光客 旅行 消費 購物 帶動 當地 經濟 開創 更多 賺錢 機會',\n",
       "       ...,\n",
       "       '其實 覺得 希望 民眾 自發 減塑 政府 方面 有所 塑膠袋 塑膠 吸管 衛生 一次性 用品 製造 廠商 課徵 環保 越重 越好 香煙 課徵 健康捐 廠商 吸收 不了 自然 提高 售價 民眾 伸手 一個 塑膠袋 付出 相信 應該 有效 減低 塑膠 使用量',\n",
       "       '出門 塑膠袋 看到 身邊 塑膠袋 收起 洗乾淨 分給 需要 攤販 重複 大樓 清潔員 垃圾袋 使用 覺得 袋子 沒壞 丟了 可惜 希望 身邊 有所 做到 塑膠袋',\n",
       "       '感謝 蘇麗瓊 執行長 柯文哲 你還 抹黑 執行長'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text, y_train, y_test = train_test_split(text, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=1000)\n",
    "token.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21625"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41703"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好像 一個 國民黨 上台 執行 真的 失望'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284, 14, 60, 179, 6, 174]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_seq[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train_seq, maxlen=20)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"before:\",len(x_train_seq[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"after:\",len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "token = Tokenizer(num_words=10000)\n",
    "token.fit_on_texts(train_text)\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen = 100)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 32)           320000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,139,713\n",
      "Trainable params: 1,139,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim=10000,\n",
    "                    input_length=100))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=256,\n",
    "                activation=\"relu\"))\n",
    "model.add(Dropout(rate = 0.35))\n",
    "\n",
    "model.add(Dense(units=1,\n",
    "                activation=\"sigmoid\"))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23637 samples, validate on 5910 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.6570 - acc: 0.5983 - val_loss: 0.6084 - val_acc: 0.6641\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.4770 - acc: 0.7989 - val_loss: 0.3648 - val_acc: 0.8459\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.2804 - acc: 0.8876 - val_loss: 0.2937 - val_acc: 0.8716\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.2127 - acc: 0.9139 - val_loss: 0.3042 - val_acc: 0.8679\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.1813 - acc: 0.9290 - val_loss: 0.3097 - val_acc: 0.8687\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.1596 - acc: 0.9388 - val_loss: 0.3203 - val_acc: 0.8660\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.1397 - acc: 0.9474 - val_loss: 0.3461 - val_acc: 0.8650\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.1246 - acc: 0.9520 - val_loss: 0.3596 - val_acc: 0.8607\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.1149 - acc: 0.9565 - val_loss: 0.3825 - val_acc: 0.8613\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.1078 - acc: 0.9585 - val_loss: 0.4038 - val_acc: 0.8591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20767624d30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=1000,\n",
    "          epochs=10, \n",
    "          verbose=2,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12663/12663 [==============================] - 0s 22us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85864329142733542"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(x_test)\n",
    "prediction[:10]\n",
    "prediction_classes=prediction.reshape(-1)\n",
    "prediction_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SentimentDict={1:\"P\",0:\"N\"}\n",
    "def display_test_Sentiment(i):\n",
    "    print(test_text[i])\n",
    "    print(\"label真實值\",SentimentDict[y_test[i]])\n",
    "    print(\"預測值\",SentimentDict[prediction_classes[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "勞工 拜託 加薪 加班 無良 企業 竄改 班表 業界 常態 員工 根本 領不到 加班費 屢次 違法 老闆 刑事 責任 放入 勞基法\n",
      "label真實值 N\n",
      "預測值 N\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "院长 辛苦\n",
      "label真實值 N\n",
      "預測值 N\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text=[\"賴清德 江宜樺 位子 腦 權力 就 不理會 人民 蔡英文 用人不當 民進黨 失望透頂 年底 選舉 民進黨 步上 國冥黨 後塵\",\n",
    "            \"不知 執政黨 有何 對策 終結 亂象 總而言之 習慣 就好 民眾 提案 禁 五星旗 法務部 不符 憲法 保障 人民 言論 自由 意旨 提案 不予 採納 金門老街 出現 景點 知名 模範街 同時 出現 中華民國 國旗 中國 五星旗 旅台鄉親 我們 厦門 習慣 看到 五星旗 元旦 五星旗 彰化 共匪窩 國安局 鎖定 西門町 六號 出口 台獨 駐點 今天 淪陷 五星旗 插滿 人行道 侵門踏戶 中國 央視 台北 西門町 大登 廣告 陸機 繞台 中共 連喊 常態化 習慣就好 邱太三 下台\",\n",
    "            \"整天 想著 企業 鬆綁 降低 稅賦 最後 經濟 果實 看到 勞工 身上 美國 稅改 政策 蠢蠢欲動 勞工低薪 只會 呼籲 廢物\",\n",
    "            \"\"\"皮鞋 拖鞋 酒駕 撞 死人 法律 想想 自己 立法 酒駕 政權 跨台\"\"\",\n",
    "            \"\"\"賴院長 已經 不信任 當初 慶富案\"\"\",\n",
    "            \"\"\"奴隸 勞工 缺德 政府 不得 民心 枉然\"\"\",\n",
    "            \"\"\"賴清 沒用 行不行 資進黨 橡皮圖章 黑心 立委 財團 老闆 不開心 怎麼辦\"\"\",\n",
    "            \"\"\"稅改 賴屎 亂修 台灣 老闆 爛 政客 繼續 吃香喝辣 賴屎\"\"\",\n",
    "            \"\"\"請問 預計 幾點 結束 昨晚 放炮 嬰兒 嚇的 整夜\"\"\",\n",
    "            \"\"\"讚 好棒 加油\"\"\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq = token.texts_to_sequences(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = model.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentimentDict[predict[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "token = Tokenizer(num_words=40000)\n",
    "token.fit_on_texts(train_text)\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen = 250)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 32)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,285,393\n",
      "Trainable params: 1,285,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim =40000,\n",
    "                    input_length = 250))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(SimpleRNN(units = 16))\n",
    "\n",
    "model.add(Dense(units= 256, activation= 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11523 samples, validate on 2881 samples\n",
      "Epoch 1/8\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=1000,\n",
    "          epochs=8, \n",
    "          verbose=2,\n",
    "          validation_split=0.2)\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,   51,  390, 2984,  592,\n",
       "       2695, 3147, 1563,  649, 1062, 1205, 2843,  674])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "token = Tokenizer(num_words=20000)\n",
    "token.fit_on_texts(train_text)\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen = 30)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA \n",
    "# pca = PCA(n_components = 20)\n",
    "# x_train = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 30, 32)            640000    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 657,025\n",
      "Trainable params: 657,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim =20000,\n",
    "                    input_length=30))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(32))\n",
    "\n",
    "model.add(Dense(units=256,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11523 samples, validate on 2881 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.6703 - acc: 0.6103 - val_loss: 0.6363 - val_acc: 0.6060\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.5102 - acc: 0.7225 - val_loss: 0.3797 - val_acc: 0.8886\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.2387 - acc: 0.9241 - val_loss: 0.2636 - val_acc: 0.9056\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.1159 - acc: 0.9613 - val_loss: 0.2556 - val_acc: 0.9098\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.0685 - acc: 0.9782 - val_loss: 0.2826 - val_acc: 0.9087\n",
      "3602/3602 [==============================] - 0s 82us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90227651308140178"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=500,\n",
    "          epochs=5, \n",
    "          verbose=2,\n",
    "          validation_split=0.2)\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text=[\"國昌 加油 深入 民心 國家 官員 苦民所苦 以德服衆 讚 永遠 支持\",\n",
    "            \"提到 酒駕 立院 戰神 國昌 提出 這種 意義 緊迫 法案 反觀 安安靜靜 時代力量 更多 支持\",\n",
    "            \"謝謝 無畏 正港 政治 努力 努力 台灣 發聲 賢能\",\n",
    "            \"\"\"黃國昌 臺灣 用心 立委 需要 時代力量 在野黨 認真 人民 發聲\"\"\",\n",
    "            \"\"\"立院 黃國昌 委員 委員 加油\"\"\",\n",
    "            \"\"\"欣賞 黃委員 認真 進度 態度\"\"\",\n",
    "            \"\"\"加油 委員\"\"\",\n",
    "            \"\"\"認真 立委 推\"\"\",\n",
    "            \"\"\"自己 重要 期許 完成 過去 總統 敢做 推動 過去 政府 推動 改革\"\"\",\n",
    "            \"\"\"讚 好棒 加油\"\"\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = token.texts_to_sequences(input_text)\n",
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=30)\n",
    "predict = model.predict_classes(pad_input_seq)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
